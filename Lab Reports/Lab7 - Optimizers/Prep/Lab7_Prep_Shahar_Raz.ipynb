{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab7 Prep Shahar Raz.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUHj53A5jM5O"
      },
      "source": [
        "# Assigment Paper:\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/55464049/114030959-8c7be680-9883-11eb-932b-44146b041417.png)\n",
        "\n",
        "\n",
        "[Adam](https://arxiv.org/pdf/1412.6980v1.pdf)\n",
        "\n",
        "[AdamW](https://arxiv.org/abs/1711.05101v3)\n",
        "\n",
        "\n",
        "[Focal Loss](https://arxiv.org/abs/1708.02002v2)\n",
        "\n",
        "[Dice](https://arxiv.org/pdf/1707.03237.pdf)\n",
        "\n",
        "Binary Cross Entropy with logits loss "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rGgUaNPFW1k"
      },
      "source": [
        "# Lec Preperation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWqc9K2QkcFD"
      },
      "source": [
        "##1. Optimizers Read & Summarize "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFuQzxgeFbQS"
      },
      "source": [
        "### 1.1 Adam\n",
        "a method for efficient stochastic optimization that only requires first-order gradients and requires little memory.\n",
        "\n",
        "Consists of 2 main methods for reaching fast to the minimum.\n",
        "\n",
        "1. Momentum: keeping the general direction of the movement. helps avoiding local minimums, and acts like a ball goin down a hill.\n",
        "![image](https://user-images.githubusercontent.com/55464049/114276061-b244ef00-9a2d-11eb-9c33-feaa59b257a7.png)\n",
        "\n",
        "\n",
        "2. RMSProp: (a better version of AdaGrad which keeping track of a historical average of square of gradient values)\n",
        "![image](https://user-images.githubusercontent.com/55464049/114275988-5e3a0a80-9a2d-11eb-854c-d0af3e60f02a.png)\n",
        ", in RMSProp we also add friction (decay) \n",
        "![image](https://user-images.githubusercontent.com/55464049/114275942-14e9bb00-9a2d-11eb-97b8-c200f235ba48.png)\n",
        "which will not allow the values to explode.\n",
        "The RMSProp arrests progress along the fast moving direction while simultaneously accelerating progress along slow moving directions, which helps it to bend directly towards the bottom.\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/55464049/114276907-6d22bc00-9a31-11eb-854a-d903d36e5793.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cfqvs_4kjOKA"
      },
      "source": [
        "### 1.2 AdamW Optimizer\n",
        "A simple modification from Adam to recover the original formulation of weight decay regularization by __decoupling__ the weight decay from the optimization steps taken. The weight decay is calculated _after_ the main calculation, and therefore does not interrupt with the them.\n",
        "\n",
        "[Link](https://towardsdatascience.com/why-adamw-matters-736223f31b5d)\n",
        "![image](https://user-images.githubusercontent.com/55464049/114277470-fe932d80-9a33-11eb-9158-9967d370654e.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzEDZJK2e6cb"
      },
      "source": [
        "### 1.3 SGD\n",
        "Basically, when we want to progress with our model:\n",
        "* we can check one example, check the error, compute the gradients and change the network. but, one example can be biased in many ways, and contains an unknown amount of noise. __1 example__.\n",
        "\n",
        "* So in order to find patterns, and go in the right direction, most likely is that we'll want to check all of our examples, average the direction, compute the loss and backdrop according to all of it.\n",
        "but, if we have a lot of data (millions-billions..) computing and averaging all the examples for each step will take VERY much time. __N examples__.\n",
        "\n",
        "* so, we try to find a middle way, here is where __SGD__ comes in! \n",
        "We'll randomly subsample our dataset to groups who each have k samples in it.\n",
        "So rather than computing the loss on the full data-set, in each step we'll compute the loss over a minibatch, and backprop accordingly. __n examples__.\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/55464049/114276150-2384a200-9a2e-11eb-9c8d-fc12851f536c.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sE1buYMk8HP"
      },
      "source": [
        "## 2. Optimizer Implemetations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLN62QIootAK"
      },
      "source": [
        "### 2.1 AdamW Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcfSUnjmjLG_"
      },
      "source": [
        "# from: https://github.com/egg-west/AdamW-pytorch/blob/master/adamW.py\n",
        "import math\n",
        "import torch\n",
        "from torch.optim.optimizer import Optimizer\n",
        "\n",
        "class AdamW(Optimizer):\n",
        "    \"\"\"Implements Adam algorithm.\n",
        "    It has been proposed in `Adam: A Method for Stochastic Optimization`_.\n",
        "    Arguments:\n",
        "        params (iterable): iterable of parameters to optimize or dicts defining\n",
        "            parameter groups\n",
        "        lr (float, optional): learning rate (default: 1e-3)\n",
        "        betas (Tuple[float, float], optional): coefficients used for computing\n",
        "            running averages of gradient and its square (default: (0.9, 0.999))\n",
        "        eps (float, optional): term added to the denominator to improve\n",
        "            numerical stability (default: 1e-8)\n",
        "        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
        "        amsgrad (boolean, optional): whether to use the AMSGrad variant of this\n",
        "            algorithm from the paper `On the Convergence of Adam and Beyond`_\n",
        "    .. _Adam\\: A Method for Stochastic Optimization:\n",
        "        https://arxiv.org/abs/1412.6980\n",
        "    .. _On the Convergence of Adam and Beyond:\n",
        "        https://openreview.net/forum?id=ryQu7f-RZ\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8,\n",
        "                 weight_decay=0, amsgrad=False):\n",
        "        if not 0.0 <= lr:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if not 0.0 <= eps:\n",
        "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
        "        if not 0.0 <= betas[1] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps,\n",
        "                        weight_decay=weight_decay, amsgrad=amsgrad)\n",
        "        super(AdamW, self).__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(AdamW, self).__setstate__(state)\n",
        "        for group in self.param_groups:\n",
        "            group.setdefault('amsgrad', False)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        \"\"\"Performs a single optimization step.\n",
        "        Arguments:\n",
        "            closure (callable, optional): A closure that reevaluates the model\n",
        "                and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n",
        "                amsgrad = group['amsgrad']\n",
        "\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                # State initialization\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    # Exponential moving average of gradient values\n",
        "                    state['exp_avg'] = torch.zeros_like(p.data)\n",
        "                    # Exponential moving average of squared gradient values\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p.data)\n",
        "                    if amsgrad:\n",
        "                        # Maintains max of all exp. moving avg. of sq. grad. values\n",
        "                        state['max_exp_avg_sq'] = torch.zeros_like(p.data)\n",
        "\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                if amsgrad:\n",
        "                    max_exp_avg_sq = state['max_exp_avg_sq']\n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                state['step'] += 1\n",
        "\n",
        "                # if group['weight_decay'] != 0:\n",
        "                #     grad = grad.add(group['weight_decay'], p.data)\n",
        "\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
        "                if amsgrad:\n",
        "                    # Maintains the maximum of all 2nd moment running avg. till now\n",
        "                    torch.max(max_exp_avg_sq, exp_avg_sq, out=max_exp_avg_sq)\n",
        "                    # Use the max. for normalizing running avg. of gradient\n",
        "                    denom = max_exp_avg_sq.sqrt().add_(group['eps'])\n",
        "                else:\n",
        "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
        "\n",
        "                bias_correction1 = 1 - beta1 ** state['step']\n",
        "                bias_correction2 = 1 - beta2 ** state['step']\n",
        "                step_size = group['lr'] * math.sqrt(bias_correction2) / bias_correction1\n",
        "\n",
        "                # p.data.addcdiv_(-step_size, exp_avg, denom)\n",
        "                p.data.add_(-step_size,  torch.mul(p.data, group['weight_decay']).addcdiv_(1, exp_avg, denom) )\n",
        "\n",
        "        return loss\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYjq9UqvquoP"
      },
      "source": [
        "### 2.2 Adam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUGDz16Yof04"
      },
      "source": [
        "import torch\n",
        "import math\n",
        "from torch.optim import Adam, SGD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBBWjGFhrkzQ"
      },
      "source": [
        "### 2.3 Choose Optimizer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw354jIVrnOH"
      },
      "source": [
        "LR = 0.01\n",
        "BATCH_SIZE = 32\n",
        "EPOCH = 12\n",
        "WD = 0.1\n",
        "\n",
        "def set_optimizer(opt_name, params, learningRate):\n",
        "    if opt_name == 'SGD':\n",
        "        optimizer = optim.SGD(params, lr=learningRate)\n",
        "    elif opt_name == 'Adam':\n",
        "        optimizer = optim.Adam(params, lr=learningRate)\n",
        "    elif opt_name == 'AdamW':\n",
        "        optimizer = AdamW(params, lr=learningRate, betas=(0.9, 0.99), weight_decay = 0.1)\n",
        "    else:\n",
        "        print(f'no {opt_name} optimizer availble, choosing Adam by default.')\n",
        "        optimizer = optim.Adam(params, lr=learningRate)\n",
        "    \n",
        "    if optimizer:\n",
        "        return optimize"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlyGZy2cq1LS"
      },
      "source": [
        "## 3. Losses Read & Summarize "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_EcZzjKrYzh"
      },
      "source": [
        "### 3.1 Cross Entropy - CE\n",
        "The Cross Entropy function is a way to measure the loss of classification problem. It must be activated after softmax function, which calculates the odds for specific class to be choosen. If the network is 100% sure of a class, it will give it score of 1, and in this case we will have no loss, which means that the NN will not be modified.\n",
        "The Step size is accoding to the loss, if the loss is high, the CE derivetive will be steep, therefor the step size will be bigger.\n",
        "\n",
        "[Stat-Quest Video](https://www.youtube.com/watch?v=6ArSys5qHAU&ab_channel=StatQuestwithJoshStarmer)\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/55464049/114303193-9563f680-9ad5-11eb-9a0b-f6cd93b6ddad.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tgp0QyMyrdfo"
      },
      "source": [
        "### 3.2 Binary Cross Entropy with logits loss\n",
        "\n",
        "[What is Logits](https://stackoverflow.com/questions/34240703/what-is-logits-what-is-the-difference-between-softmax-and-softmax-cross-entropy)\n",
        "\n",
        "\n",
        "* Logits:  the function operates on the unscaled output, that __the values are not probabilities__.\n",
        "\n",
        "* Binary Cross Entropy: Cross Entropy of only 2 categories.\n",
        "\n",
        "\n",
        "[Pytorch Link:](https://pytorch.org/docs/master/generated/torch.nn.BCEWithLogitsLoss.html#torch.nn.BCEWithLogitsLoss)\n",
        "This loss combines a Sigmoid layer and the BCELoss in one single class. This version is more numerically stable than using a plain Sigmoid followed by a BCELoss as, by combining the operations into one layer, we take advantage of the log-sum-exp trick for numerical stability.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qrwzi6FctvAw"
      },
      "source": [
        "### 3.3 Focal Loss\n",
        "Focal Loss is a modulated CE function which reduces the loss for easy / common examples, whereas keep the loss for the hard / rare examples.\n",
        "When __Gamma==0 <=> FocalLoss == CE__ , when gamma \n",
        "\n",
        "this approach is useful in many Image Classification Problems.\n",
        "![image](https://user-images.githubusercontent.com/55464049/114303741-4f5c6200-9ad8-11eb-8edd-5ec9e6cfd095.png)\n",
        "\n",
        "Another way, apart from Focal Loss, to deal with class imbalance is to introduce weights. Give high weights to the rare class and small weights to the dominating or common class. These weights are referred to as Î±.\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/55464049/114303812-aa8e5480-9ad8-11eb-9bf2-b56d8f29620b.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJcJr2cAtxSS"
      },
      "source": [
        "### 3.4 Dice\n",
        "\n",
        "Dice loss is based on the Sorensen-Dice coefficient or Tversky index, which attaches similar importance to false positives and false negatives, and is more immune to the data-imbalance issue. To further alleviate the dominating influence from easy-negative examples in training, we propose to associate training examples with dynamically adjusted weights to deemphasize easy-negative examples.\n",
        "\n",
        "Dice's formula:\n",
        "![image](https://user-images.githubusercontent.com/55464049/114304068-e83fad00-9ad9-11eb-9bb9-3ab066dddd02.png)\n",
        "\n",
        "[Dice impelemtation:](https://www.jeremyjordan.me/semantic-segmentation/#:~:text=around%20the%20cells.%20(-,Source),denotes%20perfect%20and%20complete%20overlap.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chJqu5vv5TvD"
      },
      "source": [
        "# from : https://www.jeremyjordan.me/semantic-segmentation/#:~:text=around%20the%20cells.%20(-,Source),denotes%20perfect%20and%20complete%20overlap.\n",
        "def soft_dice_loss(y_true, y_pred, epsilon=1e-6): \n",
        "    # skip the batch and class axis for calculating Dice score\n",
        "    axes = tuple(range(1, len(y_pred.shape)-1)) \n",
        "    numerator = 2. * np.sum(y_pred * y_true, axes)\n",
        "    denominator = np.sum(np.square(y_pred) + np.square(y_true), axes)\n",
        "    \n",
        "    return 1 - np.mean((numerator + epsilon) / (denominator + epsilon)) # average over classes and batch\n",
        "    # thanks @mfernezir for catching a bug in an earlier version of this implementation!"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HtFZd5trGzd"
      },
      "source": [
        "## 4. Losses Implementations:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2LojdxJrUXg"
      },
      "source": [
        "### 4.1  Focal Loss\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVY-owMBrT9J"
      },
      "source": [
        "def focal_loss(pt, alpha, gama):\n",
        "    return (-1) * alpha * ((1 - pt)**gama) * np.log(pt)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKlJWRvAfGwy"
      },
      "source": [
        "## Snippets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "mbyFeglcfJU6",
        "outputId": "81206945-02fb-45bd-896d-371a311c0f38"
      },
      "source": [
        "import torch\n",
        "import math\n",
        "from torch.optim import Adam, SGD\n",
        "from torch.optim.optimizer import Optimizer, required\n",
        "\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out),\n",
        ")\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "\n",
        "learning_rate = 1e-4\n",
        "\n",
        "display(model.parameters())\n",
        "for parm in model.parameters():\n",
        "    print(f' {parm.shape} \\t')\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "for t in range(500):\n",
        "\n",
        "    y_pred = model(x)\n",
        "\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7f61f790e2d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            " torch.Size([100, 1000]) \t\n",
            " torch.Size([100]) \t\n",
            " torch.Size([10, 100]) \t\n",
            " torch.Size([10]) \t\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:89: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "99 62.18852996826172\n",
            "199 1.151323676109314\n",
            "299 0.011353669688105583\n",
            "399 0.000170590152265504\n",
            "499 1.551429932078463e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8S3J1Tefdfr"
      },
      "source": [
        "%%shell\n",
        "jupyter nbconvert --to html /content/SecondPracticeML.ipynb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AaIbUUWfLAR"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}